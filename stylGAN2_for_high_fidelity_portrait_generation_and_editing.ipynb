{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/karunyavalar/TNSDC-_Generative-AI/blob/main/stylGAN2_for_high_fidelity_portrait_generation_and_editing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'rezero-rem-anime-faces-for-gan-training:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1899492%2F3119506%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240329%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240329T115457Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D50a6ace6a65f1d80788403268b0c7c5318f6920c43ffe7063fc46f1910c884e4ba54bd0d5291b897e37425415e858b5e3214606384dc0cdf7b5aae09f44314bede548483326b00c18d6c6f653fdb8457374a6f8f8e3ad994fc574550fa08a92638250fdb038347a46eb88f44a35f114ed2a3d0b150587618483379030b05d584dfe2d9cc79ae70fc62e141c7fa3312fb7d4e58632bd8823d60053b1b0d7889f8c52ad772ca05def48e772d460b0cf24adf6723546f4a9ac54acee1f98e483601e3f6781d469714fc5d7370926fa37277fb6870140c4f6369a7cf56dddff1d7e00ea5267858636ea5e2e437d82653a2d8f722c8097e479b4df5ebf248537473a3'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vbWMw_OEFO3",
        "outputId": "a6f2e102-e160-442a-9008-1c2be84aa1de"
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading rezero-rem-anime-faces-for-gan-training, 1150368645 bytes compressed\n",
            "[==================================================] 1150368645 bytes downloaded\n",
            "Downloaded and uncompressed: rezero-rem-anime-faces-for-gan-training\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train your own GAN in a few lines of code!\n",
        "See original StyleGAN2 ADA github repo here: https://github.com/NVlabs/stylegan2-ada-pytorch\n",
        "\n",
        "By using a pre-trained model along with data heavy data augmentation, we can train our own GAN with a very limited dataset (<1000 images)."
      ],
      "metadata": {
        "id": "nT2VPR01EFO9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspng ninja imageio-ffmpeg==0.4.3\n",
        "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch\n",
        "!pip install googledrivedownloader\n",
        "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "%cd ./stylegan2-ada-pytorch"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-31T13:48:24.536166Z",
          "iopub.execute_input": "2022-01-31T13:48:24.536515Z",
          "iopub.status.idle": "2022-01-31T13:48:45.893699Z",
          "shell.execute_reply.started": "2022-01-31T13:48:24.536448Z",
          "shell.execute_reply": "2022-01-31T13:48:45.892758Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vgbb1VRwEFPB",
        "outputId": "7b1ada35-d65b-4c74-ddeb-bb3b83255d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspng\n",
            "  Downloading pyspng-0.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.9/205.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio-ffmpeg==0.4.3\n",
            "  Downloading imageio_ffmpeg-0.4.3-py3-none-manylinux2010_x86_64.whl (26.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.9/26.9 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from pyspng) (1.25.2)\n",
            "Installing collected packages: ninja, pyspng, imageio-ffmpeg\n",
            "  Attempting uninstall: imageio-ffmpeg\n",
            "    Found existing installation: imageio-ffmpeg 0.4.9\n",
            "    Uninstalling imageio-ffmpeg-0.4.9:\n",
            "      Successfully uninstalled imageio-ffmpeg-0.4.9\n",
            "Successfully installed imageio-ffmpeg-0.4.3 ninja-1.11.1.1 pyspng-0.1.1\n",
            "Cloning into 'stylegan2-ada-pytorch'...\n",
            "remote: Enumerating objects: 131, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
            "remote: Total 131 (delta 0), reused 1 (delta 0), pack-reused 128\u001b[K\n",
            "Receiving objects: 100% (131/131), 1.13 MiB | 3.45 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.10/dist-packages (0.4)\n",
            "/content/stylegan2-ada-pytorch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download pre-trained model\n",
        "A pre-trained model on Danbooru portraits will be used"
      ],
      "metadata": {
        "id": "jmGFry2BEFPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez\"\n",
        "network_pkl = './model_%s.pkl' % model_id\n",
        "gdd.download_file_from_google_drive(file_id=model_id, dest_path=network_pkl)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-31T13:48:49.625688Z",
          "iopub.execute_input": "2022-01-31T13:48:49.625964Z",
          "iopub.status.idle": "2022-01-31T13:48:52.006712Z",
          "shell.execute_reply.started": "2022-01-31T13:48:49.625934Z",
          "shell.execute_reply": "2022-01-31T13:48:52.005902Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsU6kMruEFPE",
        "outputId": "e695c947-ef96-4875-e075-cbd9b666e298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez into ./model_1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez.pkl... Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python dataset_tool.py --source=/kaggle/input/rezero-rem-anime-faces-for-gan-training/rem_images/rem_preprocessed_512 --dest=./datasets/rem.zip"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-31T14:00:36.418736Z",
          "iopub.execute_input": "2022-01-31T14:00:36.419519Z",
          "iopub.status.idle": "2022-01-31T14:00:59.355881Z",
          "shell.execute_reply.started": "2022-01-31T14:00:36.419472Z",
          "shell.execute_reply": "2022-01-31T14:00:59.355096Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWOiw3znEFPF",
        "outputId": "0e9b2195-3970-4432-bbf7-bd7c59b7b0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 725/725 [00:18<00:00, 39.68it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training will take a long time, make sure you have enough GPU hours available (minimum 10 hours required for good results)\n",
        "Do !python train.py --help to see the different optional arguments available.\n",
        "If resuming training, edit --remsume to your pkl file"
      ],
      "metadata": {
        "id": "1YUG4K8KEFPG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --outdir ./results --snap=4 --cfg=paper512 --data=./datasets/rem.zip --augpipe=\"bg\" --mirror=True --metrics=None --resume=./model_1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez.pkl --augpipe=\"bg\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-31T14:01:10.778112Z",
          "iopub.execute_input": "2022-01-31T14:01:10.77838Z",
          "iopub.status.idle": "2022-01-31T14:02:25.030593Z",
          "shell.execute_reply.started": "2022-01-31T14:01:10.778351Z",
          "shell.execute_reply": "2022-01-31T14:02:25.029674Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNwJb3UCEFPH",
        "outputId": "56d08f75-e1ae-4307-b3e4-db1e414bd2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 4,\n",
            "  \"network_snapshot_ticks\": 4,\n",
            "  \"metrics\": [],\n",
            "  \"random_seed\": 0,\n",
            "  \"training_set_kwargs\": {\n",
            "    \"class_name\": \"training.dataset.ImageFolderDataset\",\n",
            "    \"path\": \"./datasets/rem.zip\",\n",
            "    \"use_labels\": false,\n",
            "    \"max_size\": 725,\n",
            "    \"xflip\": true,\n",
            "    \"resolution\": 512\n",
            "  },\n",
            "  \"data_loader_kwargs\": {\n",
            "    \"pin_memory\": true,\n",
            "    \"num_workers\": 3,\n",
            "    \"prefetch_factor\": 2\n",
            "  },\n",
            "  \"G_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Generator\",\n",
            "    \"z_dim\": 512,\n",
            "    \"w_dim\": 512,\n",
            "    \"mapping_kwargs\": {\n",
            "      \"num_layers\": 8\n",
            "    },\n",
            "    \"synthesis_kwargs\": {\n",
            "      \"channel_base\": 32768,\n",
            "      \"channel_max\": 512,\n",
            "      \"num_fp16_res\": 4,\n",
            "      \"conv_clamp\": 256\n",
            "    }\n",
            "  },\n",
            "  \"D_kwargs\": {\n",
            "    \"class_name\": \"training.networks.Discriminator\",\n",
            "    \"block_kwargs\": {},\n",
            "    \"mapping_kwargs\": {},\n",
            "    \"epilogue_kwargs\": {\n",
            "      \"mbstd_group_size\": 8\n",
            "    },\n",
            "    \"channel_base\": 32768,\n",
            "    \"channel_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"D_opt_kwargs\": {\n",
            "    \"class_name\": \"torch.optim.Adam\",\n",
            "    \"lr\": 0.0025,\n",
            "    \"betas\": [\n",
            "      0,\n",
            "      0.99\n",
            "    ],\n",
            "    \"eps\": 1e-08\n",
            "  },\n",
            "  \"loss_kwargs\": {\n",
            "    \"class_name\": \"training.loss.StyleGAN2Loss\",\n",
            "    \"r1_gamma\": 0.5\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"batch_size\": 64,\n",
            "  \"batch_gpu\": 8,\n",
            "  \"ema_kimg\": 20,\n",
            "  \"ema_rampup\": null,\n",
            "  \"ada_target\": 0.6,\n",
            "  \"augment_kwargs\": {\n",
            "    \"class_name\": \"training.augment.AugmentPipe\",\n",
            "    \"xflip\": 1,\n",
            "    \"rotate90\": 1,\n",
            "    \"xint\": 1,\n",
            "    \"scale\": 1,\n",
            "    \"rotate\": 1,\n",
            "    \"aniso\": 1,\n",
            "    \"xfrac\": 1\n",
            "  },\n",
            "  \"resume_pkl\": \"./model_1WNQELgHnaqMTq3TlrnDaVkyrAH8Zrjez.pkl\",\n",
            "  \"ada_kimg\": 100,\n",
            "  \"run_dir\": \"./results/00000-rem-mirror-paper512-bg-resumecustom\"\n",
            "}\n",
            "\n",
            "Output directory:   ./results/00000-rem-mirror-paper512-bg-resumecustom\n",
            "Training data:      ./datasets/rem.zip\n",
            "Training duration:  25000 kimg\n",
            "Number of GPUs:     1\n",
            "Number of images:   725\n",
            "Image resolution:   512\n",
            "Conditional model:  False\n",
            "Dataset x-flips:    True\n",
            "\n",
            "Creating output directory...\n",
            "Launching processes...\n",
            "Loading training set...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 3 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "Num images:  1450\n",
            "Image shape: [3, 512, 512]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stylegan2-ada-pytorch/train.py\", line 538, in <module>\n",
            "    main() # pylint: disable=no-value-for-parameter\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1157, in __call__\n",
            "    return self.main(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1078, in main\n",
            "    rv = self.invoke(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 1434, in invoke\n",
            "    return ctx.invoke(self.callback, **ctx.params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/core.py\", line 783, in invoke\n",
            "    return __callback(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/click/decorators.py\", line 33, in new_func\n",
            "    return f(get_current_context(), *args, **kwargs)\n",
            "  File \"/content/stylegan2-ada-pytorch/train.py\", line 531, in main\n",
            "    subprocess_fn(rank=0, args=args, temp_dir=temp_dir)\n",
            "  File \"/content/stylegan2-ada-pytorch/train.py\", line 383, in subprocess_fn\n",
            "    training_loop.training_loop(rank=rank, **args)\n",
            "  File \"/content/stylegan2-ada-pytorch/training/training_loop.py\", line 150, in training_loop\n",
            "    G = dnnlib.util.construct_class_by_name(**G_kwargs, **common_kwargs).train().requires_grad_(False).to(device) # subclass of torch.nn.Module\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1152, in to\n",
            "    return self._apply(convert)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
            "    module._apply(fn)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 802, in _apply\n",
            "    module._apply(fn)\n",
            "  [Previous line repeated 1 more time]\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 825, in _apply\n",
            "    param_applied = fn(param)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1150, in convert\n",
            "    return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None, non_blocking)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 302, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note the training was cancelled as I have already previously trained a model (see ../input/rezero-rem-anime-faces-for-gan-training/pre-trained/network-snapshot-000108.pkl)"
      ],
      "metadata": {
        "id": "YR1m06Y3EFPI"
      }
    }
  ]
}